# services/gemini_service_v2.py
import logging
from google import genai
from google.genai.errors import APIError

logger = logging.getLogger('GeminiServiceV2')
logger.setLevel(logging.INFO)

class GeminiServiceV2:
    # ğŸ”´ ä¿®æ”¹é€™è£¡ï¼šå°‡é è¨­å€¼æ”¹ç‚º "gemini-2.0-flash" (æ ¹æ“šæ‚¨æ¸¬è©¦çµæœå¯ç”¨çš„æ¨¡å‹)
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash"):
        if not api_key:
            logger.warning("âš ï¸ Gemini API Key æœªè¨­å®š")
            self.client = None
        else:
            try:
                self.client = genai.Client(api_key=api_key)
                self.model_name = model_name
                logger.info(f"Gemini V2 Ready (Model: {model_name})")
            except Exception as e:
                logger.error(f"Gemini Init Failed: {e}")
                self.client = None

    def generate_churn_explanation(self, input_features: dict, prediction_result: dict, feature_importance: str) -> str:
        if not self.client:
            return "AI æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œä½†æ ¹æ“šæ¨¡å‹é æ¸¬ï¼Œè©²å®¢æˆ¶é¢¨éšªç‹€æ³å¦‚ä¸Šæ‰€ç¤ºã€‚"

        prob = float(prediction_result.get('probability', 0.0))
        is_churn = int(prediction_result.get('prediction', 0))
        formatted_features = "\n".join([f"- {k}: {v}" for k, v in input_features.items()])

        tone = "è©²å®¢æˆ¶ç‚º**æ¥µé«˜æµå¤±é¢¨éšª**ï¼Œè«‹æä¾›å¼·åŠ›æŒ½ç•™æ–¹æ¡ˆã€‚" if prob > 0.7 else \
               "è©²å®¢æˆ¶æœ‰**æ½›åœ¨æµå¤±é¢¨éšª**ï¼Œå»ºè­°é é˜²æ€§é—œæ‡·ã€‚" if prob > 0.3 else \
               "è©²å®¢æˆ¶**ç‹€æ³ç©©å®š**ï¼Œå°‹æ±‚äº¤å‰éŠ·å”®æ©Ÿæœƒã€‚"

        prompt = f"""
        ä½ æ˜¯ä¸€ä½éŠ€è¡Œé¢¨éšªåˆ†æå¸«ã€‚è«‹æ ¹æ“šæ•¸æ“šç”Ÿæˆç°¡å ±ã€‚
        ã€åˆ†æç›®æ¨™ã€‘{tone}
        ã€å®¢æˆ¶æ•¸æ“šã€‘{formatted_features}
        ã€æ¨¡å‹è¨ºæ–·ã€‘æµå¤±æ©Ÿç‡: {prob:.1%}, é æ¸¬: {'âš ï¸ æµå¤±' if is_churn else 'âœ… ç•™å­˜'}
        ã€é—œéµå› å­ã€‘{feature_importance}
        
        è«‹æä¾›ï¼š1.é¢¨éšªæ´å¯Ÿ 2.é—œéµå› ç´ è§£è®€ 3.å…·é«”è¡Œå‹•å»ºè­°(ROIå°å‘)ã€‚150å­—å…§ã€‚
        """

        try:
            # å˜—è©¦å‘¼å« AI
            response = self.client.models.generate_content(model=self.model_name, contents=prompt)
            if not response.text:
                return "AI å›å‚³å…§å®¹ç‚ºç©ºã€‚"
            return response.text.strip()
        except Exception as e:
            # ğŸ”¥ é‡è¦ï¼šå°‡çœŸæ­£çš„éŒ¯èª¤å°åœ¨çµ‚ç«¯æ©Ÿï¼Œæ–¹ä¾¿é™¤éŒ¯
            print(f"âŒ Gemini Error Details: {str(e)}")
            # å›å‚³åŒ…å«éŒ¯èª¤éƒ¨åˆ†çš„è¨Šæ¯ï¼Œè®“å‰ç«¯ä¹Ÿèƒ½ç¨å¾®çœ‹åˆ°
            return f"AI åˆ†æå¤±æ•—: {str(e)[:50]}..."